{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Detection Model - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the advanced diabetes detection model with interactive predictions and risk assessment.\n",
    "\n",
    "## Features Included\n",
    "- Multi-algorithm ensemble predictions\n",
    "- Risk stratification analysis\n",
    "- Personalized health recommendations\n",
    "- Feature importance visualization\n",
    "- Model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes dataset\n",
    "data = pd.read_csv('your_diabetes_data.csv')\n",
    "\n",
    "print('Dataset shape:', data.shape)\n",
    "print('\\nFirst few rows:')\n",
    "print(data.head())\n",
    "print('\\nBasic statistics:')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "data_clean = data.fillna(data.mean())\n",
    "\n",
    "# Separate features and target\n",
    "X = data_clean.drop('Outcome', axis=1) if 'Outcome' in data_clean.columns else data_clean.iloc[:, :-1]\n",
    "y = data_clean['Outcome'] if 'Outcome' in data_clean.columns else data_clean.iloc[:, -1]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print('Features shape:', X_scaled.shape)\n",
    "print('Target distribution:', y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training (All Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train multiple models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', probability=True),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, verbose=0),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f'{name} trained successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "results = {}\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results[name] = {'Accuracy': accuracy, 'AUC': auc}\n",
    "    print(f'{name}: Accuracy={accuracy:.4f}, AUC={auc:.4f}')\n",
    "\n",
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "print('\\nModel Comparison:')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Risk Assessment & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make ensemble predictions and assess risk\n",
    "def assess_diabetes_risk(patient_data):\n",
    "    \"\"\"\n",
    "    Assess diabetes risk based on patient data\n",
    "    patient_data: array or list of features\n",
    "    \"\"\"\n",
    "    patient_scaled = scaler.transform([patient_data])\n",
    "    \n",
    "    # Get predictions from all models\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    for name, model in trained_models.items():\n",
    "        pred = model.predict(patient_scaled)[0]\n",
    "        proba = model.predict_proba(patient_scaled)[0][1]\n",
    "        predictions.append(pred)\n",
    "        probabilities.append(proba)\n",
    "    \n",
    "    # Ensemble prediction (majority voting + average probability)\n",
    "    avg_probability = np.mean(probabilities)\n",
    "    \n",
    "    # Risk assessment\n",
    "    if avg_probability < 0.3:\n",
    "        risk_level = 'LOW RISK'\n",
    "        recommendations = ['Maintain current lifestyle', 'Regular exercise (150 min/week)', 'Annual check-ups']\n",
    "    elif avg_probability < 0.7:\n",
    "        risk_level = 'MEDIUM RISK'\n",
    "        recommendations = ['Increase physical activity', 'Dietary modifications', 'Quarterly monitoring']\n",
    "    else:\n",
    "        risk_level = 'HIGH RISK'\n",
    "        recommendations = ['Consult healthcare provider', 'Medication consideration', 'Monthly monitoring']\n",
    "    \n",
    "    return {\n",
    "        'risk_score': avg_probability,\n",
    "        'risk_level': risk_level,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "print('Risk Assessment Function Defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Example Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example patient data\n",
    "patient_example = [6, 148, 72, 35, 0, 33.6, 0.627, 50]  # Sample feature values\n",
    "\n",
    "# Get risk assessment\n",
    "risk_assessment = assess_diabetes_risk(patient_example)\n",
    "\n",
    "print('Patient Risk Assessment:')\n",
    "print(f\"Risk Score: {risk_assessment['risk_score']:.4f}\")\n",
    "print(f\"Risk Level: {risk_assessment['risk_level']}\")\n",
    "print(f\"Recommendations: {risk_assessment['recommendations']}\")\n",
    "\n",
    "print('\\n--- Assessment Complete ---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
